{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from datasets import Dataset as HFDataset\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/blairjdaniel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/blairjdaniel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/blairjdaniel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import string\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = pd.DataFrame(ds['train']).head(10000)\n",
    "ds_test = pd.DataFrame(ds['test']).head(10000)\n",
    "ds_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove punctuation from the text col\n",
    "def remove_punctuation(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "    return text\n",
    "\n",
    "# Run the function on the datasets\n",
    "ds_train['text_no_punct'] = ds_train['text'].apply(lambda x: remove_punctuation(x))\n",
    "ds_test['text_no_punct'] = ds_test['text'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    # Convert text to lowercase and tokenize using nltk\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/blairjdaniel/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Run the tokenizer function on the df\n",
    "nltk.download('punkt_tab')\n",
    "ds_train['text_tokenized'] = ds_train['text_no_punct'].apply(lambda x: tokenize(x))\n",
    "ds_test['text_tokenized'] = ds_test['text_no_punct'].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_no_punct</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>I rented I AM CURIOUSYELLOW from my video stor...</td>\n",
       "      <td>[i, rented, i, am, curiousyellow, from, my, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "      <td>I Am Curious Yellow is a risible and pretentio...</td>\n",
       "      <td>[i, am, curious, yellow, is, a, risible, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>[if, only, to, avoid, making, this, type, of, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>This film was probably inspired by Godards Mas...</td>\n",
       "      <td>[this, film, was, probably, inspired, by, goda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh brotherafter hearing about this ridiculous ...</td>\n",
       "      <td>[oh, brotherafter, hearing, about, this, ridic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0   \n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0   \n",
       "2  If only to avoid making this type of film in t...      0   \n",
       "3  This film was probably inspired by Godard's Ma...      0   \n",
       "4  Oh, brother...after hearing about this ridicul...      0   \n",
       "\n",
       "                                       text_no_punct  \\\n",
       "0  I rented I AM CURIOUSYELLOW from my video stor...   \n",
       "1  I Am Curious Yellow is a risible and pretentio...   \n",
       "2  If only to avoid making this type of film in t...   \n",
       "3  This film was probably inspired by Godards Mas...   \n",
       "4  Oh brotherafter hearing about this ridiculous ...   \n",
       "\n",
       "                                      text_tokenized  \n",
       "0  [i, rented, i, am, curiousyellow, from, my, vi...  \n",
       "1  [i, am, curious, yellow, is, a, risible, and, ...  \n",
       "2  [if, only, to, avoid, making, this, type, of, ...  \n",
       "3  [this, film, was, probably, inspired, by, goda...  \n",
       "4  [oh, brotherafter, hearing, about, this, ridic...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each tokenized review\n",
    "ds_train['text_length'] = ds_train['text_tokenized'].apply(len)\n",
    "\n",
    "# Calculate minimum, maximum, and average number of words\n",
    "min_length = ds_train['text_length'].min()\n",
    "max_length = ds_train['text_length'].max()\n",
    "avg_length = ds_train['text_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each tokenized review\n",
    "ds_test['text_length'] = ds_test['text_tokenized'].apply(len)\n",
    "\n",
    "# Calculate minimum, maximum, and average number of words\n",
    "min_length = ds_test['text_length'].min()\n",
    "max_length = ds_test['text_length'].max()\n",
    "avg_length = ds_test['text_length'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to rid of stop words in English\n",
    "def remove_stopwords(tokens):    \n",
    "    stop_words = stopwords.words('english')\n",
    "    return [word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the stop words function on the df\n",
    "ds_train['text_no_stop'] = ds_train['text_tokenized'].apply(remove_stopwords)\n",
    "ds_test['text_no_stop'] = ds_test['text_tokenized'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.to_csv('/Users/blairjdaniel/lighthouse/lighthouse/LLM-Sentiment-Analysis-lhl/csv_files/train.csv')\n",
    "ds_test.to_csv('/Users/blairjdaniel/lighthouse/lighthouse/LLM-Sentiment-Analysis-lhl/csv_files/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
